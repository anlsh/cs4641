{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M-dS4mS8Tqn7"
   },
   "source": [
    "**CS 4641 Project 1: Anish Moorthy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "emOnmruhyklr",
    "outputId": "3d9af4fb-b646-4819-a76b-e26bbdee043a"
   },
   "outputs": [],
   "source": [
    "# INSTALLING REQUIRED PACKAGES\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YeeBS20D9Hl9"
   },
   "source": [
    "**Initial Setup**: Here I simply import modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQnxeB9PTpqk"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import time\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import itertools\n",
    "try:\n",
    "    from google.colab import files\n",
    "except ImportError:\n",
    "  print(\"Not running on colab\")\n",
    "\n",
    "# Hopefully memory is less of an issue with colab, but I'll keep this in case\n",
    "NP_DATA_TYPE = np.float64\n",
    "\n",
    "dataset = None\n",
    "CIFAR = True\n",
    "IMDB = False\n",
    "\n",
    "itermode = None\n",
    "ITER_RETRAIN = 1\n",
    "ITER_BOOST = 2\n",
    "ITER_NONE = 3\n",
    "\n",
    "lsource = None\n",
    "SKLEARN = 1\n",
    "KERAS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Kz-0f38dgd2"
   },
   "source": [
    "Here I define some modular functions which will implement learning processes. Note that these functions allow incoming data to be transformed in various ways (such as normalization), and that this normalization is performed ONLY on the part of the data used for training: thus information from the test set does not leak into our training process, and the test/validation sets are transformed later according to the scalers' processing of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VWet7P3reHhO"
   },
   "outputs": [],
   "source": [
    "def train_with_crossval(LearnerType, LearnerParams,\n",
    "                        ProcessorType, ProcessorArgs,\n",
    "                        training_data, training_labels, \n",
    "                        val_fraction, num_evals,\n",
    "                        verbose=True):\n",
    "\n",
    "    # I needed a bit more flexibility than what the default cross-validation\n",
    "    # function provided, so I implement my own here. This function creates\n",
    "    # multiple train-val splits and trains the learner (given params) on each\n",
    "    # of them, returning an array of (learner, preprocessor, train_acc, val_acc)\n",
    "    # tuples\n",
    "    \n",
    "    # Note that it's not \"traditional\" cross-validation in that the data is \n",
    "    # split into folds and each fold is used: rather the creation of splits is\n",
    "    # random\n",
    "    \n",
    "    # score_function should produce some sort of score(true_params, predicted_params)\n",
    "    \n",
    "    \n",
    "    score_function = metrics.accuracy_score\n",
    "    results = [None] * num_evals\n",
    "    \n",
    "    for i in range(num_evals):\n",
    "        foobar = train_test_split(training_data, training_labels, \n",
    "                               test_size=val_fraction, shuffle=True)\n",
    "        tmp_train_data, tmp_val_data, tmp_train_labels, tmp_val_labels = foobar\n",
    "      \n",
    "        scaler = ProcessorType(**ProcessorArgs)\n",
    "        scaler.fit(tmp_train_data)\n",
    "        tmp_train_data = scaler.transform(tmp_train_data)\n",
    "        tmp_val_data = scaler.transform(tmp_val_data)\n",
    "       \n",
    "        start_time = time.time()\n",
    "        learner = LearnerType(**LearnerParams)\n",
    "        learner.fit(tmp_train_data, tmp_train_labels)\n",
    "        end_time = time.time()\n",
    "        train_time = end_time - start_time\n",
    "      \n",
    "        train_score = score_function(learner.predict(tmp_train_data),\n",
    "                                  tmp_train_labels)\n",
    "        val_score = score_function(learner.predict(tmp_val_data),\n",
    "                                    tmp_val_labels)\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"Validator \", i, \" finished in \", train_time,\"s\"\n",
    "                  + \"with (train, val) scores of \", (train_score, val_score))\n",
    "      \n",
    "        results[i] = (learner, scaler, train_score, val_score)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"All validations complete.\")\n",
    "\n",
    "    return results\n",
    "   \n",
    "def perf_over_iterations_nonincremental(LearnerType, hyperparams, \n",
    "                                        ProcessorType, ProcessorArgs,\n",
    "                                        train_examples, test_examples,\n",
    "                                        iterations_array):\n",
    "    # Iterations_array: an array of integers to train the model for before\n",
    "    # evaluating its performance\n",
    "    \n",
    "    score = metrics.accuracy_score\n",
    "    \n",
    "    print(\"WARNINING... You are running the non-incremental evaluator, \" \\\n",
    "         + \"which will probably be very slow. You know what you're getting into, right?\")\n",
    "    \n",
    "    train_x, train_y = train_examples\n",
    "    test_x, test_y = test_examples\n",
    "    \n",
    "    iterations_nparray = np.array(iterations_array)\n",
    "    train_accuracy_array = np.zeros(len(iterations_array))\n",
    "    test_accuracy_array = np.zeros(len(iterations_array))\n",
    "    \n",
    "    for index, num_iters in enumerate(iterations_array):\n",
    "        \n",
    "        hyperparams_with_iter = hyperparams.copy()\n",
    "        hyperparams_with_iter[\"max_iter\"] = num_iters\n",
    "        learner, scaler, train_acc, _ = train_with_crossval(LearnerType, \n",
    "                                                            hyperparams_with_iter,\n",
    "                                                            ProcessorType, ProcessorArgs,\n",
    "                                                            train_examples[0], \n",
    "                                                            train_examples[1], \n",
    "                                                            .01, 1)[0]\n",
    "        \n",
    "        train_accuracy_array[index] = train_acc\n",
    "        test_accuracy_array[index] = score(learner.predict(scaler.transform(test_x)), \n",
    "                                           test_y)\n",
    "        \n",
    "    return (iterations_nparray, train_accuracy_array, test_accuracy_array)\n",
    "  \n",
    "def perf_over_iterations_boost(learner, scaler,\n",
    "                               train_examples, test_examples,\n",
    "                              verbose=True):\n",
    "    \n",
    "    train_x, train_y = train_examples\n",
    "    test_x, test_y = test_examples\n",
    "    \n",
    "    scaled_train_x = scaler.transform(train_x)\n",
    "    scaled_test_x = scaler.transform(test_x)\n",
    "    \n",
    "    train_accs = []\n",
    "    test_accs = []\n",
    "    \n",
    "    train_claccs = []\n",
    "    test_claccs = []\n",
    "    \n",
    "    for train_pred in learner.staged_predict(scaled_train_x):\n",
    "        train_accs.append(sklearn.metrics.accuracy_score(train_pred, train_y))\n",
    "        train_claccs.append(get_confusion_and_class_accs(train_y, train_pred)[1])\n",
    "        \n",
    "    for test_pred in learner.staged_predict(scaled_test_x):\n",
    "        test_accs.append(sklearn.metrics.accuracy_score(test_pred, test_y))\n",
    "        test_claccs.append(get_confusion_and_class_accs(test_y, test_pred)[1])\n",
    "       \n",
    "    if verbose:\n",
    "        print(\"Train class accuracies over iterations\")\n",
    "        print(np.array(train_claccs))\n",
    "        print(\"Test class accuracies over iterations\")\n",
    "        print(np.array(test_claccs))\n",
    "    \n",
    "    return np.arange(len(train_accs)), np.array(train_accs), np.array(test_accs)\n",
    "  \n",
    "def flatten_data_array(X):\n",
    "    # Given an array X where X[i] is the ith data tensor, return an array X'\n",
    "    # where X'[i] is the flattened data of the ith data tensor\n",
    "    num_datapoints = X.shape[0]\n",
    "    datum_size = np.prod(X.shape[1:])\n",
    "    return X.reshape([num_datapoints, datum_size])\n",
    "  \n",
    "def augmented_split(*args, test_size=None, shuffle=True, random_state=None):\n",
    "  \n",
    "    if test_size < 0 or test_size >= 1:\n",
    "        raise RuntimeError(\"Cant handle test fraction of \", str(test_size))\n",
    "    \n",
    "    if test_size == 0:\n",
    "        out = [(a, None) for a in args]\n",
    "        return itertools.chain(*out)\n",
    "    else:\n",
    "      return train_test_split(*args, \n",
    "                              test_size=test_size, \n",
    "                              shuffle=shuffle,\n",
    "                              random_state=random_state)\n",
    "\n",
    "def get_confusion_and_class_accs(truth_labels, predictions):\n",
    "\n",
    "    confusion_mat = sklearn.metrics.confusion_matrix(truth_labels, predictions)\n",
    "    # The counts are always in increasing order of label, which is good!\n",
    "    unique, counts = np.unique(truth_labels, return_counts=True)\n",
    "    \n",
    "    # https://stackoverflow.com/questions/19602187/numpy-divide-each-row-by-a-vector-element\n",
    "    percent_confusion = (confusion_mat / counts[:,None]).astype(np.float16)\n",
    "    class_percents = np.diagonal(percent_confusion)\n",
    "    \n",
    "    return percent_confusion, class_percents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SzgJubZ2W8uh"
   },
   "source": [
    "## **DATASET SELECTION**: \n",
    "Only run one of the cells below. The first will load the CIFAR-10 dataset. The second will load the IMDB sentiment analysis dataset. If both are run, only the most recently-run dataset will be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FaZEPFcIXKTM"
   },
   "outputs": [],
   "source": [
    "# CIFAR DATASET\n",
    "from skimage.color import rgb2gray\n",
    "\n",
    "dataset = CIFAR\n",
    "\n",
    "# Configurable flags\n",
    "CIFAR_GRAYSCALE = True\n",
    "\n",
    "if not CIFAR_GRAYSCALE:\n",
    "  print(\"NOT GRAYSCALING PICTURES!\")\n",
    "\n",
    "# NOTE: Don't worry about the train and test sets being merged below: we will \n",
    "# split the data into train and testing sets again before training\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_all, labels = np.concatenate([x_train, x_test]), np.concatenate([y_train, y_test])\n",
    "labels = labels.ravel()\n",
    "\n",
    "# NOTE: I preprocess the CIFAR-10 dataset in a few ways. First, the pictures\n",
    "# are converted to grayscale images (greatly reducing dimensionality/complexity)\n",
    "# if the relevant flag is set\n",
    "\n",
    "if CIFAR_GRAYSCALE:\n",
    "    x_all = rgb2gray(x_all).astype(NP_DATA_TYPE, copy=False)\n",
    "\n",
    "x_all = flatten_data_array(x_all)\n",
    "\n",
    "print(\"Full Data, Label shapes = \", x_all.shape, \", \", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2StzsR4c6eC"
   },
   "outputs": [],
   "source": [
    "# IMDB DATASET\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import os.path\n",
    "\n",
    "dataset = IMDB\n",
    "\n",
    "# Changeable parameter\n",
    "MAX_WORD_FEATURES = 10000\n",
    "ONEHOTS_FILENAME = \"imdb-onehots.gz\"\n",
    "LABELS_FILENAME = \"imdb-labels.gz\"\n",
    "\n",
    "def clean_text(raw_review):\n",
    "    # Function to convert a raw review to a string of words\n",
    "    \n",
    "    # Import modules\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    \n",
    "    review_text = BeautifulSoup(raw_review, 'html.parser').get_text() # Remove HTML\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) # Remove non-letters \n",
    "    words = letters_only.lower().split() # Convert to lower case, split into individual words\n",
    "    stops = set(stopwords.words(\"english\")) # Remove stop words (use of sets makes this faster)               \n",
    "    meaningful_words = [w for w in words if not w in stops]                             \n",
    "    porter = PorterStemmer() # Reduce word to stem of word\n",
    "    stemmed_words = [porter.stem(w) for w in meaningful_words]\n",
    "    joined_words = ( \" \".join( stemmed_words )) # Join the words back into one string separated by space\n",
    "    return joined_words \n",
    "\n",
    "def apply_cleaning_function_to_series(X):\n",
    "    print('Cleaning data')\n",
    "    start_time = time.time()\n",
    "    cleaned_X = []\n",
    "    for element in X:\n",
    "        cleaned_X.append(clean_text(element))\n",
    "    print ('Finished in ', str((time.time() - start_time)/60), \" minutes\")\n",
    "    return cleaned_X\n",
    "\n",
    "if not os.path.isfile(ONEHOTS_FILENAME + \".npz\"):\n",
    "    nltk.download('stopwords')\n",
    "    print(\"one-hots not created yet: cleaning and saving to file\")\n",
    "    print(\"Expect this to take about 10-15 minutes\")\n",
    "    data = pd.read_csv('https://gitlab.com/michaelallen1966/00_python_snippets_and_recipes/raw/master/machine_learning/data/IMDb.csv')\n",
    "    \n",
    "    x_cleaned = apply_cleaning_function_to_series(data[\"review\"])\n",
    "    labels = np.array(data[\"sentiment\"]).ravel()\n",
    "    \n",
    "    # Free up memory!\n",
    "    data = None\n",
    "    vectorizer = CountVectorizer(analyzer=\"word\",\n",
    "                                 tokenizer=None,\n",
    "                                 preprocessor=None,\n",
    "                                 stop_words=None,\n",
    "                                 ngram_range=(1,1),\n",
    "                                 max_features=MAX_WORD_FEATURES)\n",
    "    vectorizer.fit(x_cleaned)\n",
    "    x_all = vectorizer.transform(x_cleaned)\n",
    "    x_cleaned = None\n",
    "    scipy.sparse.save_npz(ONEHOTS_FILENAME, x_all)\n",
    "    np.savetxt(LABELS_FILENAME, labels)\n",
    "else:\n",
    "    print(\"loading one-hots from file\")\n",
    "    start_time = time.time()\n",
    "    x_all = scipy.sparse.load_npz(ONEHOTS_FILENAME + \".npz\")\n",
    "    labels = np.loadtxt(LABELS_FILENAME)\n",
    "    end_time = time.time()\n",
    "    print(\"Finished loading one-hots in \", (end_time - start_time)/60, \" minutes\")\n",
    "\n",
    "print(\"Full Data, Label shapes = \", x_all.shape, \", \", labels.shape)\n",
    "\n",
    "# files.download(ONEHOTS_FILENAME + \".npz\")\n",
    "# files.download(LABELS_FILENAME)\n",
    "# files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jcx7itFGbq27"
   },
   "source": [
    "## **Choosing Learner**\n",
    "Here I define various types of learners and sets of hyperparameters which I would like to test them with. Run whichever setup corresponds to the learner you would like to test. Each also defines parameters such as train/val/test fractions and how the data should be normalized\n",
    "\n",
    "Each cell defines a variable named hyperparam_configs which is a list of dictionaries containing hyperparameter names and corresponding values (the creation location is based on which dataset is selected, so make sure you're looking at the right spot!) If you would like to test a single set of hyperparameters, just comment out/delete all but one element of the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRcc3Po8i58O"
   },
   "outputs": [],
   "source": [
    "# SCIKIT DECISION TREE\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as NoPruningDecisionTree\n",
    "\n",
    "LearnerType = NoPruningDecisionTree\n",
    "itermode = ITER_NONE\n",
    "lsource = SKLEARN\n",
    "\n",
    "if dataset == CIFAR:\n",
    "\n",
    "    NUM_VALIDATIONS = 5\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = 0.2\n",
    "    VAL_OVER_TRAIN = 0.2\n",
    "    \n",
    "    ProcessorType = sklearn.preprocessing.StandardScaler\n",
    "    ProcessorArgs = {\"with_mean\": True, \"with_std\": True}\n",
    "         \n",
    "    hyperparam_configs = [\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": 5, \"min_samples_split\": 4, \"max_leaf_nodes\": None},\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": None, \"min_samples_split\": 2, \"max_leaf_nodes\": 100},\n",
    "    ]\n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, .4, .5, .6, .7, .8]\n",
    "    \n",
    "elif dataset == IMDB:\n",
    "  \n",
    "    NUM_VALIDATIONS = 10\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = .2\n",
    "    VAL_OVER_TRAIN = .2 \n",
    "  \n",
    "    ProcessorType = sklearn.feature_extraction.text.TfidfTransformer\n",
    "    ProcessorArgs = {\"use_idf\": True, \"sublinear_tf\": True}\n",
    "    \n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, .4, .5, .6, .7, .8]\n",
    "    \n",
    "    hyperparam_configs = [\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": 1, \"min_samples_split\": 2, \"max_leaf_nodes\": None},\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": 5, \"min_samples_split\": 4, \"max_leaf_nodes\": None},\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": None, \"min_samples_split\": 2, \"max_leaf_nodes\": 100},\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": None, \"min_samples_split\": 2, \"max_leaf_nodes\": None},\n",
    "        {\"criterion\": \"entropy\", \"max_depth\": 6, \"min_samples_split\": 50, \"max_leaf_nodes\": None},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f6aFjK0cDRuA"
   },
   "outputs": [],
   "source": [
    "# SUPPORT VECTOR MACHINES\n",
    "\n",
    "from sklearn.svm import SVC as SupportVectorClassifier\n",
    "\n",
    "LearnerType = SupportVectorClassifier\n",
    "itermode = ITER_RETRAIN\n",
    "lsource = SKLEARN\n",
    "\n",
    "\n",
    "if dataset == CIFAR:\n",
    "\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = 0.5\n",
    "    VAL_OVER_TRAIN = 0.25\n",
    "    NUM_VALIDATIONS = 1\n",
    "\n",
    "    ProcessorType = sklearn.preprocessing.StandardScaler\n",
    "    ProcessorArgs = {\"with_mean\": True, \"with_std\": True}\n",
    "    \n",
    "    PERF_ITERATIONS_ARRAY = [0, 500, 1000, 2000, 3000]\n",
    "    PERF_TRAINSIZE_ARRAY = [.1, .2, .4, .6, .8]\n",
    "    \n",
    "    hyperparam_configs = [\n",
    "        {\"C\": 1.0, \"kernel\": \"rbf\", \"degree\": 0, \"shrinking\": True, \"max_iter\": 2000},\n",
    "    ]\n",
    "    \n",
    "elif dataset == IMDB:\n",
    "\n",
    "  # TODO Run this and see whether same kind of results hold\n",
    "  # TODO used to be .8\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = .2\n",
    "    VAL_OVER_TRAIN = .2\n",
    "    NUM_VALIDATIONS = 5\n",
    "    \n",
    "    hyperparam_configs = [\n",
    "        {\"C\": 1.0, \"kernel\": \"linear\", \"degree\": 0, \"shrinking\": True, \"max_iter\": 2000},\n",
    "    ]\n",
    "  \n",
    "    ProcessorType = sklearn.feature_extraction.text.TfidfTransformer\n",
    "    ProcessorArgs = {\"use_idf\": True, \"sublinear_tf\": True}\n",
    "\n",
    "    PERF_ITERATIONS_ARRAY = [1, 50, 100, 200, 500, 750, 1000, 2000, 3000]\n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, 4, .5, .6, .7, .8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o6vsOTkuuJBh"
   },
   "outputs": [],
   "source": [
    "# K NEAREST NEIGHBOURS\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics.pairwise import cosine_distances as cosdist\n",
    "\n",
    "LearnerType = KNeighborsClassifier\n",
    "itermode = ITER_NONE\n",
    "lsource = SKLEARN\n",
    "\n",
    "if dataset == CIFAR:\n",
    "\n",
    "    FRACTION_OF_DATASET = .2\n",
    "    NUM_VALIDATIONS = 5\n",
    "    TEST_OVER_TOTAL = 0.2\n",
    "    VAL_OVER_TRAIN = 0.2\n",
    "    \n",
    "    ProcessorType = sklearn.preprocessing.StandardScaler\n",
    "    ProcessorArgs = {\"with_mean\": True, \"with_std\": True}\n",
    "         \n",
    "    hyperparam_configs = [\n",
    "        # RUN 0\n",
    "        # {\"n_neighbors\": 1, \"p\": 2, \"metric\": \"minkowski\", \"weights\": \"uniform\"},\n",
    "        # {\"n_neighbors\": 5, \"p\": 2, \"metric\": \"minkowski\", \"weights\": \"uniform\"},\n",
    "        # {\"n_neighbors\": 3, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"uniform\"},\n",
    "        \n",
    "        # RUN 1\n",
    "        #{\"n_neighbors\": 3, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"distance\"},\n",
    "        # {\"n_neighbors\": 7, \"p\": 2, \"metric\": \"minkowski\", \"weights\": \"distance\"}, # Takes an hour to run for some reason?\n",
    "        {\"n_neighbors\": 20, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"distance\"},\n",
    "        # {\"n_neighbors\": 8, \"p\": 5, \"metric\": \"minkowski\", \"weights\": \"uniform\"}, # ALSO takes an hour!?!\n",
    "    ]\n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .4, .6, .8]\n",
    "    \n",
    "elif dataset == IMDB:\n",
    "  \n",
    "    FRACTION_OF_DATASET = .15\n",
    "    NUM_VALIDATIONS = 5\n",
    "    TEST_OVER_TOTAL = .2\n",
    "    VAL_OVER_TRAIN = .2 \n",
    "    ProcessorType = sklearn.feature_extraction.text.TfidfTransformer\n",
    "    ProcessorArgs = {\"use_idf\": True, \"sublinear_tf\": True}\n",
    "    \n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, .4, .5, .6, .7, .8]\n",
    "    \n",
    "    hyperparam_configs = [ \n",
    "        # {\"n_neighbors\": 3, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"distance\"},\n",
    "        # {\"n_neighbors\": 10, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"distance\"},\n",
    "        # {\"n_neighbors\": 15, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"distance\"},\n",
    "        {\"n_neighbors\": 1, \"p\": 2, \"metric\": \"minkowski\", \"weights\": \"uniform\"},\n",
    "        {\"n_neighbors\": 5, \"p\": 2, \"metric\": \"minkowski\", \"weights\": \"uniform\"},\n",
    "        # {\"n_neighbors\": 3, \"p\": 1, \"metric\": \"minkowski\", \"weights\": \"uniform\"},     \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ksWke4hsb9Fv"
   },
   "outputs": [],
   "source": [
    "# BOOSTING\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier as NoPruningDecisionTree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "LearnerType = AdaBoostClassifier\n",
    "itermode = ITER_BOOST\n",
    "lsource = SKLEARN\n",
    "\n",
    "if dataset == CIFAR:\n",
    "\n",
    "    NUM_VALIDATIONS = 1\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = 0.2\n",
    "    VAL_OVER_TRAIN = 0.2\n",
    "    \n",
    "    ProcessorType = sklearn.preprocessing.StandardScaler\n",
    "    ProcessorArgs = {\"with_mean\": True, \"with_std\": True}\n",
    "         \n",
    "    weak_learner = NoPruningDecisionTree(criterion=\"entropy\",\n",
    "                                         max_depth=5, \n",
    "                                         min_samples_split=4)\n",
    "    hyperparam_configs = [\n",
    "        {\"base_estimator\": weak_learner, \"n_estimators\": 20, \"learning_rate\": 1},\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 5, \"learning_rate\": 2},\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 5, \"learning_rate\": 5},\n",
    "        # {\"base_estimator\": None, \"n_estimators\": 50, \"learning_rate\": 1},\n",
    "        # {\"base_estimator\": None, \"n_estimators\": 5, \"learning_rate\": .5},\n",
    "        \n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 50, \"learning_rate\": 1}, # Default params\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 25, \"learning_rate\": 2},\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 5, \"learning_rate\": 5},\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 5, \"learning_rate\": .5},\n",
    "    ]\n",
    "    \n",
    "\n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, .4, .5, .6, .7, .8]\n",
    "    PERF_ITERATIONS_ARRAY = None\n",
    "    \n",
    "elif dataset == IMDB:\n",
    "  \n",
    "    NUM_VALIDATIONS = 1\n",
    "    FRACTION_OF_DATASET = 1\n",
    "    TEST_OVER_TOTAL = .2\n",
    "    VAL_OVER_TRAIN = .2 \n",
    "  \n",
    "    ProcessorType = sklearn.feature_extraction.text.TfidfTransformer\n",
    "    ProcessorArgs = {\"use_idf\": True, \"sublinear_tf\": True}\n",
    "    \n",
    "    PERF_TRAINSIZE_ARRAY = [.02, .1, .2, .3, .4, .5, .6, .7, .8]\n",
    "    PERF_ITERATIONS_ARRAY = None\n",
    "    \n",
    "    weak_learner = NoPruningDecisionTree(criterion=\"entropy\",\n",
    "                                         max_depth=None, \n",
    "                                         min_samples_split=2,\n",
    "                                        max_leaf_nodes=100)\n",
    "    \n",
    "    hyperparam_configs = [\n",
    "        {\"base_estimator\": weak_learner, \"n_estimators\": 30, \"learning_rate\": 1},\n",
    "        # {\"base_estimator\": weak_learner, \"n_estimators\": 10, \"learning_rate\": 2},\n",
    "        # {\"base_estimator\": None, \"n_estimators\": 5, \"learning_rate\": 1},\n",
    "        # {\"base_estimator\": None, \"n_estimators\": 5, \"learning_rate\": .5},\n",
    "        # {\"base_estimator\": None, \"n_estimators\": 5, \"learning_rate\": 2},\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hzx4O2a-ZyYT"
   },
   "source": [
    "Now to split our data into testing and training sets so that we can do some learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6AvzKQPZxhJ"
   },
   "outputs": [],
   "source": [
    "# Split data into test/test sets\n",
    "x_reduced, _, labels_reduced, _ = augmented_split(x_all, labels, \n",
    "                                       test_size=1-FRACTION_OF_DATASET)\n",
    "print(\"Data and label shapes are: \", x_reduced.shape, labels_reduced.shape)\n",
    "train_data, test_data, \\\n",
    "    train_labels, test_labels = train_test_split(x_reduced, labels_reduced,\n",
    "                                                 test_size=TEST_OVER_TOTAL)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IcgMqJPMdDMY"
   },
   "source": [
    "And finally I attempt to actually learn something :|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "inwaDd4fdOQv"
   },
   "outputs": [],
   "source": [
    "print(LearnerType.__name__ + \"\\n-----------------------------------\")\n",
    "print(\"Fraction of Dataset: \", FRACTION_OF_DATASET)\n",
    "print(\"Test over total\", TEST_OVER_TOTAL)\n",
    "print(\"Train over val\", VAL_OVER_TRAIN)\n",
    "print(\"Preprocessor type, args\", ProcessorType.__name__,\" \", ProcessorArgs)\n",
    "print(\"Num validations: \", NUM_VALIDATIONS)\n",
    "\n",
    "learners = [None] * len(hyperparam_configs)\n",
    "accuracies = [None] * len(hyperparam_configs)\n",
    "\n",
    "for index, hyperparams in enumerate(hyperparam_configs):\n",
    "  \n",
    "    print(\"\\n========================================================\")\n",
    "    print(LearnerType.__name__ + \" \" + str(index))\n",
    "    print(\"Hyperparams \", hyperparams)\n",
    "\n",
    "    start_time = time.time()\n",
    "    results = train_with_crossval(LearnerType=LearnerType, \n",
    "                                  LearnerParams=hyperparams, \n",
    "                                  ProcessorType=ProcessorType,\n",
    "                                  ProcessorArgs=ProcessorArgs,\n",
    "                                  training_data=train_data, \n",
    "                                  training_labels=train_labels,\n",
    "                                  val_fraction=VAL_OVER_TRAIN, \n",
    "                                  num_evals=NUM_VALIDATIONS,\n",
    "                                  verbose=True)\n",
    "    end_time = time.time()\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(\"Total time spent training is \" + str(end_time - start_time) + \" seconds\")\n",
    "    \n",
    "    learners_and_transformers = [r[:2] for r in results]\n",
    "    train_accuracies = np.array([r[2] for r in results])\n",
    "    val_accuracies = np.array([r[3] for r in results])\n",
    "    \n",
    "    mean_train_accuracy, mean_train_stdv = np.mean(train_accuracies), np.std(train_accuracies)\n",
    "    mean_val_accuracy, mean_val_stdv = np.mean(val_accuracies), np.std(val_accuracies)\n",
    "    \n",
    "    learners[index] = learners_and_transformers\n",
    "    accuracies[index] = (mean_train_accuracy, mean_val_accuracy)\n",
    "    stdvs = (mean_train_stdv, mean_val_stdv)\n",
    "    \n",
    "    print(\"Standard deviation of (train-acc, val-acc) = \", stdvs)\n",
    "    print(\"~~~~~~~> (train-acc, val-acc) = \", accuracies[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PpkunZGU4gYJ"
   },
   "source": [
    "**Test Set Evaluation:** Here we choose the set of hyperparameters which has the best validation accuracy, and evaluate it on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oRwTBCf4euA"
   },
   "outputs": [],
   "source": [
    "if lsource == SKLEARN:\n",
    "    # best_hyperparams = hyperparam_configs[0]\n",
    "    best_learner_index = np.argmax([acc[1] for acc in accuracies])\n",
    "    best_hyperparams = hyperparam_configs[best_learner_index]\n",
    "    # Recall that we return an array of learners for each validation run, so take the first\n",
    "    best_learner_and_scaler = learners[best_learner_index][0]\n",
    "    best_learner, best_scaler = best_learner_and_scaler\n",
    "\n",
    "    print(\"The best-performing series of learners was \" + str(LearnerType.__name__) \\\n",
    "          + str(best_learner_index))\n",
    "    print(\"Hyperparameters for this learner were \", best_hyperparams)\n",
    "\n",
    "    test_predictions = best_learner.predict(best_scaler.transform(test_data))\n",
    "    test_accuracy = metrics.accuracy_score(test_predictions, test_labels)\n",
    "    print(\"On the test set, accuracy is: \", test_accuracy)\n",
    "\n",
    "    confusion, class_accs = get_confusion_and_class_accs(test_labels, test_predictions)\n",
    "\n",
    "    np.set_printoptions(precision=3)\n",
    "    print(\"Confusion Matrix: \")\n",
    "    print(confusion)\n",
    "    print(\"Class Accuracies: \", class_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0hAhp-5DguB"
   },
   "source": [
    "**Performance over dataset size** : Taking several *fractions of the static training set* as training sets, train the learner (using the best hyperparams) on each set and report performance on the training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4KoKl4NeER9M"
   },
   "outputs": [],
   "source": [
    "if lsource == SKLEARN:\n",
    "    perf_fracs = np.array(PERF_TRAINSIZE_ARRAY)\n",
    "    perf_trainfracs_accs = np.zeros(len(PERF_TRAINSIZE_ARRAY))\n",
    "    perf_testfracs_accs = np.zeros(len(PERF_TRAINSIZE_ARRAY))\n",
    "\n",
    "    for index, train_fraction in enumerate(PERF_TRAINSIZE_ARRAY):\n",
    "\n",
    "        start_time = time.time()\n",
    "        perf_trainfracs_data, _, \\\n",
    "            perf_trainfracs_labels, __ = train_test_split(train_data, train_labels,\n",
    "                                                         test_size=1-train_fraction)\n",
    "\n",
    "        learner, scaler, train_acc, _ = train_with_crossval(LearnerType, \n",
    "                                                            best_hyperparams,\n",
    "                                                            ProcessorType,\n",
    "                                                            ProcessorArgs,\n",
    "                                                            perf_trainfracs_data,\n",
    "                                                            perf_trainfracs_labels,\n",
    "                                                            .01, 1, verbose=False)[0]\n",
    "\n",
    "        perf_trainfracs_accs[index] = train_acc\n",
    "        test_predictions = learner.predict(scaler.transform(test_data))\n",
    "        perf_testfracs_accs[index] = metrics.accuracy_score(test_predictions,\n",
    "                                                             test_labels)\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"\\n===============================================================\")\n",
    "        print(\"Fraction \" + str(train_fraction) +\": \" + str(index) + \" finished in \" + str((end_time - start_time)/60) + \" mins\")\n",
    "        print(\"Train/Test Accuracies: \", (train_acc, perf_testfracs_accs[index]))\n",
    "        confusion, class_accs = get_confusion_and_class_accs(test_labels, test_predictions)\n",
    "        print(\"Class accuracies: \", class_accs)\n",
    "\n",
    "    print(perf_trainfracs_accs)\n",
    "    print(perf_testfracs_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JTFeD3haLRMv"
   },
   "outputs": [],
   "source": [
    "if lsource == SKLEARN:\n",
    "    # Graphing performance over time...\n",
    "    plt.title(\"Accuracy vs Training Size\")\n",
    "    plt.xlabel('Percentage of data used for training')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    print(perf_fracs)\n",
    "    print(perf_trainfracs_accs)\n",
    "    print(perf_testfracs_accs)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.plot(perf_fracs, perf_trainfracs_accs, label=\"Train data\") \n",
    "    plt.plot(perf_fracs, perf_testfracs_accs, label=\"Test data\")\n",
    "    plt.ylim(ymin=0)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "seqVP3ya_6IX"
   },
   "source": [
    "**Performance over time(iterations)**: Using *the same training/test sets every time*, calculate the performance on (train/test) data as a function of the number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nZYg3EoAxwI"
   },
   "outputs": [],
   "source": [
    "if lsource == SKLEARN:\n",
    "    # best_hyperparams = hyperparam_configs[0]\n",
    "    start_time = time.time()\n",
    "    if itermode == ITER_RETRAIN:\n",
    "        # Training function (might take a lot of time)\n",
    "        start_time = time.time()\n",
    "        perf_iters, perf_trainits_accs, \\\n",
    "                    perf_testits_accs = perf_over_iterations_nonincremental(LearnerType=LearnerType,\n",
    "                                                                            hyperparams=best_hyperparams,\n",
    "                                                                            ProcessorType=ProcessorType,\n",
    "                                                                            ProcessorArgs=ProcessorArgs,\n",
    "                                                                            train_examples=(train_data, train_labels),\n",
    "                                                                            test_examples=(test_data, test_labels),\n",
    "                                                                            iterations_array=PERF_ITERATIONS_ARRAY,)\n",
    "    elif itermode == ITER_NONE:\n",
    "      print(\"Whaddaya doing!? Can't iterate over this learner ya goof\")\n",
    "\n",
    "    elif itermode == ITER_BOOST:\n",
    "        perf_iters, perf_trainits_accs, \\\n",
    "                    perf_testits_accs = perf_over_iterations_boost(learner=best_learner,\n",
    "                                                                  scaler=best_scaler,\n",
    "                                                                  train_examples=(train_data, train_labels),\n",
    "                                                                  test_examples=(test_data, test_labels))\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(\"Iteration eval finished in \", str((end_time - start_time)/60), \" mins\")\n",
    "    print(\"Train accs\", perf_trainits_accs)\n",
    "    print(\"Test accs\", perf_testits_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XR-VPUh0KA70"
   },
   "outputs": [],
   "source": [
    "if lsource == SKLEARN:\n",
    "    # Graphing performance over time...\n",
    "    plt.title(\"Accuracy vs Number Iterations\")\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    # plt.ylim(ymin=0)\n",
    "    plt.plot(perf_iters, perf_trainits_accs, label=\"Train data\")\n",
    "    plt.plot(perf_iters, perf_testits_accs, label=\"Test data\")\n",
    "    # plt.ylim(ymin=0)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "amoorthy8-sklearner-notebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
